# Integration Architecture - Complete System Overview

## ğŸ”„ How Everything Connects

This document explains how the **existing Resume_Builder modules** (`src/`, `data/`) integrate with the **new React frontend** (`frontend/`) via the **FastAPI backend** (`backend/`).

---

## ğŸ“Š Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      USER INTERFACE (React)                          â”‚
â”‚                                                                      â”‚
â”‚  Pages:                                                              â”‚
â”‚  â”œâ”€â”€ Registration (multi-step with resume upload)                   â”‚
â”‚  â”œâ”€â”€ Login                                                           â”‚
â”‚  â”œâ”€â”€ Dashboard (workflow selector)                                  â”‚
â”‚  â”œâ”€â”€ Manual Workflow (paste JD â†’ optimize)                          â”‚
â”‚  â”œâ”€â”€ Adzuna Workflow (search jobs â†’ match â†’ optimize)               â”‚
â”‚  â””â”€â”€ Profile                                                         â”‚
â”‚                                                                      â”‚
â”‚  Components:                                                         â”‚
â”‚  â””â”€â”€ Shared (Button, Card, LoadingSpinner, Transition)              â”‚
â”‚                                                                      â”‚
â”‚  Services (Axios API calls):                                        â”‚
â”‚  â”œâ”€â”€ authService.js         â†’ /api/auth/*                           â”‚
â”‚  â”œâ”€â”€ resumeService.js        â†’ /api/resume/*                        â”‚
â”‚  â”œâ”€â”€ jobService.js           â†’ /api/jobs/*                          â”‚
â”‚  â””â”€â”€ generationService.js    â†’ /api/generate/*                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â”‚ HTTP/JSON (REST API)
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BACKEND LAYER (FastAPI)                           â”‚
â”‚                                                                      â”‚
â”‚  API Routers (backend/routers/):                                    â”‚
â”‚  â”œâ”€â”€ auth.py          â†’ Authentication (login, register, logout)    â”‚
â”‚  â”œâ”€â”€ resume.py        â†’ Resume upload, parse, update, delete        â”‚
â”‚  â”œâ”€â”€ jobs.py          â†’ Adzuna search, job matching (FAISS)         â”‚
â”‚  â””â”€â”€ generation.py    â†’ Manual/Adzuna workflows, DOCX export        â”‚
â”‚                                                                      â”‚
â”‚  Services (backend/services/):                                      â”‚
â”‚  â”œâ”€â”€ resume_service.py      â†’ Wraps src/parsers/resume_parser.py   â”‚
â”‚  â”œâ”€â”€ jd_service.py          â†’ Wraps src/parsers/jd_parser.py        â”‚
â”‚  â”œâ”€â”€ matching_service.py    â†’ Wraps src/analysis + src/rag          â”‚
â”‚  â”œâ”€â”€ generation_service.py  â†’ Wraps src/generation + src/export     â”‚
â”‚  â””â”€â”€ adzuna_service.py      â†’ Adzuna API integration                â”‚
â”‚                                                                      â”‚
â”‚  Database (SQLAlchemy ORM):                                         â”‚
â”‚  â”œâ”€â”€ User (extended with phone, address, profile_pic, resume data) â”‚
â”‚  â”œâ”€â”€ Subscription (free/pro plans)                                  â”‚
â”‚  â”œâ”€â”€ UsageRecord (monthly limits)                                   â”‚
â”‚  â”œâ”€â”€ Resume (saved optimizations)                                   â”‚
â”‚  â””â”€â”€ Session (JWT tracking)                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â”‚ Python imports
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               EXISTING MODULES (src/)                                â”‚
â”‚                                                                      â”‚
â”‚  Parsers (src/parsers/):                                            â”‚
â”‚  â”œâ”€â”€ resume_parser.py   â†’ Extract data from PDF/DOCX resumes        â”‚
â”‚  â””â”€â”€ jd_parser.py       â†’ Parse job descriptions                    â”‚
â”‚                                                                      â”‚
â”‚  Analysis (src/analysis/):                                          â”‚
â”‚  â””â”€â”€ skill_matcher.py   â†’ Keyword matching with synonyms/abbrevs    â”‚
â”‚                                                                      â”‚
â”‚  Vector Store (src/vectorstore/):                                   â”‚
â”‚  â”œâ”€â”€ embeddings.py      â†’ sentence-transformers/all-MiniLM-L6-v2    â”‚
â”‚  â””â”€â”€ vector_db.py       â†’ In-memory vector database                 â”‚
â”‚                                                                      â”‚
â”‚  RAG (src/rag/):                                                    â”‚
â”‚  â””â”€â”€ retriever.py       â†’ Semantic matching (66%+ similarity)       â”‚
â”‚                                                                      â”‚
â”‚  Generation (src/generation/):                                      â”‚
â”‚  â”œâ”€â”€ llm_service.py     â†’ OpenAI/Anthropic API wrapper              â”‚
â”‚  â”œâ”€â”€ prompts.py         â†’ WHR format templates (20-25 bullets)      â”‚
â”‚  â””â”€â”€ generator.py       â†’ Resume optimization orchestration         â”‚
â”‚                                                                      â”‚
â”‚  Export (src/export/):                                              â”‚
â”‚  â””â”€â”€ docx_formatter.py  â†’ ATS-friendly DOCX generation              â”‚
â”‚                                                                      â”‚
â”‚  Models (src/models.py):                                            â”‚
â”‚  â””â”€â”€ Pydantic schemas (Resume, JobDescription, Experience, etc.)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”— **Integration Points**

### **1. Resume Upload & Parsing (Registration Step 2)**

**User Action:**
- User uploads resume in registration form

**Flow:**
```
Frontend (RegisterPage.jsx)
  â””â”€> POST /api/resume/parse (FormData with resume file)
       â””â”€> backend/routers/resume.py::parse_resume()
            â””â”€> backend/services/resume_service.py::parse_resume()
                 â””â”€> src/parsers/resume_parser.py::ResumeParser.parse_resume()
                      â””â”€> Returns: Resume object (Pydantic)
                           â””â”€> Converted to JSON dict
                                â””â”€> Sent back to frontend
                                     â””â”€> Frontend displays education, experience, skills
```

**Data Flow:**
```python
# resume_service.py uses existing parser
from src.parsers.resume_parser import ResumeParser

parser = ResumeParser()
resume: Resume = parser.parse_resume(file_path)  # From src/

# Convert Resume object to dict for JSON response
parsed_data = {
    "contact_info": {...},
    "education": [...],
    "experience": [...],
    "skills": [...],
    "projects": [...],
    "certifications": [...]
}
```

---

### **2. Manual Workflow (Paste JD â†’ Optimize Resume)**

**User Action:**
- User pastes job description text
- Clicks "Optimize Resume"

**Flow:**
```
Frontend (ManualWorkflow.jsx)
  â””â”€> POST /api/generate/manual { jd_text: "..." }
       â””â”€> backend/routers/generation.py::generate_from_manual_jd()
            â”œâ”€> jd_service.parse_job_description(jd_text)
            â”‚    â””â”€> src/parsers/jd_parser.py::JDParser.parse()
            â”œâ”€> matching_service.calculate_match_score(resume, jd)
            â”‚    â”œâ”€> src/analysis/skill_matcher.py::SkillMatcher.match_skills()
            â”‚    â””â”€> src/rag/retriever.py::RAGRetriever.retrieve_relevant_sections()
            â”œâ”€> generation_service.optimize_resume(resume, jd)
            â”‚    â””â”€> src/generation/generator.py::ResumeGenerator.optimize_resume()
            â”‚         â”œâ”€> src/generation/llm_service.py (GPT-3.5)
            â”‚         â””â”€> src/generation/prompts.py (WHR templates)
            â””â”€> generation_service.export_to_docx(optimized_resume)
                 â””â”€> src/export/docx_formatter.py::DOCXFormatter.export_resume()
                      â””â”€> Returns: DOCX file path
```

**Response:**
```json
{
  "original_resume": { ... },
  "optimized_resume": {
    "professional_summary": "Optimized...",
    "experience": [
      {
        "company": "...",
        "job_title": "...",
        "responsibilities": [
          "**Architected** end-to-end data pipelines...",  // Bold keywords
          "**Reduced** processing time by 40%..."          // Metrics added
        ]
      }
    ],
    "skills": { "Technical Skills": [...], "GenAI Skills": [...] }
  },
  "match_analysis": {
    "keyword_match": { "percentage": 75.5, ... },
    "semantic_match": { "percentage": 82.3, ... },
    "overall_score": 78.2
  },
  "docx_url": "/api/generate/download/resume_abc123.docx"
}
```

---

### **3. Adzuna Workflow (Search Jobs â†’ Match â†’ Optimize)**

**User Action:**
- User enters search filters (title, location, salary)
- Clicks "Search Jobs"

**Flow Part 1: Search & Match**
```
Frontend (AdzunaWorkflow.jsx)
  â””â”€> POST /api/jobs/search { query: "data engineer", location: "Atlanta, GA", filters: {...} }
       â””â”€> backend/routers/jobs.py::search_jobs()
            â””â”€> backend/services/adzuna_service.py::search_jobs()
                 â””â”€> Adzuna API call (HTTPS)
                      â””â”€> Returns: List of 20 jobs

  â””â”€> POST /api/jobs/match { resume_text: "...", jobs: [...] }
       â””â”€> backend/routers/jobs.py::match_resume_to_jobs()
            â””â”€> backend/services/matching_service.py::match_resume_to_jobs()
                 â”œâ”€> src/vectorstore/embeddings.py::create_embedding(resume)
                 â”œâ”€> For each job:
                 â”‚    â”œâ”€> src/vectorstore/embeddings.py::create_embedding(job)
                 â”‚    â””â”€> Calculate cosine similarity
                 â””â”€> Returns: Jobs sorted by similarity (>10%)
```

**Response:**
```json
[
  {
    "id": "adzuna_123456",
    "title": "Senior Data Engineer",
    "company": "TechCorp",
    "description": "...",
    "similarity_score": 85.5  // <-- Added by FAISS matching
  },
  ...
]
```

**Flow Part 2: User Selects Job â†’ Optimize**
```
Frontend (JobCard.jsx - user clicks "Optimize Resume")
  â””â”€> POST /api/generate/adzuna { job_id: "...", job_data: {...} }
       â””â”€> backend/routers/generation.py::generate_from_adzuna_job()
            â””â”€> Same flow as manual workflow (parse JD, match, optimize, export)
```

---

### **4. Skill Matching (Keyword + Semantic)**

**Integration:**
```python
# backend/services/matching_service.py

from src.analysis.skill_matcher import SkillMatcher
from src.rag.retriever import RAGRetriever

# Keyword matching (60% weight)
skill_match_result = SkillMatcher().match_skills(resume, jd)
# Returns: match_percentage, matched_skills, missing_skills

# Semantic matching (40% weight)
semantic_matches = RAGRetriever().retrieve_relevant_sections(resume, jd)
# Returns: List of (resume_section, jd_requirement, similarity_score)

# Combined score
overall_score = (keyword_match * 0.6) + (semantic_match * 0.4)
```

**Existing Features Used:**
- âœ… Abbreviation matching (ADF = Azure Data Factory)
- âœ… Synonym matching (Python = PySpark)
- âœ… Skills extracted from experience bullets
- âœ… RAG-based semantic similarity

---

### **5. Resume Optimization (LLM)**

**Integration:**
```python
# backend/services/generation_service.py

from src.generation.generator import ResumeGenerator
from src.generation.llm_service import get_default_llm_service

llm = get_default_llm_service()  # GPT-3.5-turbo
generator = ResumeGenerator(llm)

# Optimize using existing prompts (WHR format, 20-25 bullets)
optimized_resume = generator.optimize_resume(resume, jd)
```

**Existing Features Used:**
- âœ… WHR (What-How-Result) format
- âœ… 20-25 bullets per experience section
- âœ… Bold keywords using **markdown** syntax
- âœ… Metrics and quantification
- âœ… Skills optimization (preserves all original skills)
- âœ… Project optimization

---

### **6. DOCX Export (ATS-Friendly)**

**Integration:**
```python
# backend/services/generation_service.py

from src/export/docx_formatter import DOCXFormatter

formatter = DOCXFormatter()
formatter.export_resume(optimized_resume, output_path)
```

**Existing Features Used:**
- âœ… Clickable hyperlinks (GitHub, LinkedIn)
- âœ… Bold keyword formatting (parses **text**)
- âœ… Skills tables (Technical Skills + GenAI Skills)
- âœ… Text justification
- âœ… No bullet symbols (ATS-friendly)

---

## ğŸ“¦ **Data Models Mapping**

### **Database â†’ Pydantic â†’ JSON**

```python
# User stores parsed resume data in JSON column
User.resume_parsed_data = {
    "contact_info": {...},
    "education": [...],
    "experience": [...],
    "skills": [...]
}

# When needed, convert to Pydantic Resume object
from src.models import Resume

resume = Resume(**user.resume_parsed_data)

# Pass to existing generators
optimized = generator.optimize_resume(resume, jd)

# Convert back to dict for JSON response
optimized_dict = {
    "professional_summary": optimized.professional_summary,
    "experience": [exp.dict() for exp in optimized.experience],
    ...
}
```

---

## ğŸ”§ **Configuration & Dependencies**

### **Shared Dependencies**

Both backend and existing modules use:
- `openai` - GPT-3.5-turbo API
- `sentence-transformers` - all-MiniLM-L6-v2 embeddings
- `python-docx` - DOCX generation
- `pydantic` - Data validation

### **Environment Variables**

```env
# .env (shared)
OPENAI_API_KEY=sk-proj-...
ANTHROPIC_API_KEY=...
ADZUNA_APP_ID=...
ADZUNA_APP_KEY=...

# Backend only
DATABASE_URL=sqlite:///./resume_builder.db
JWT_SECRET_KEY=...
```

---

## ğŸ“‚ **File Organization**

```
Resume_Builder/
â”œâ”€â”€ frontend/                  # NEW: React UI
â”‚   â”œâ”€â”€ src/components/
â”‚   â”œâ”€â”€ src/services/          # Axios API calls
â”‚   â””â”€â”€ src/context/
â”‚
â”œâ”€â”€ backend/                   # NEW: FastAPI backend
â”‚   â”œâ”€â”€ routers/               # API endpoints
â”‚   â”œâ”€â”€ services/              # ğŸ”— Integration layer (uses src/)
â”‚   â”œâ”€â”€ models/                # Database models
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ src/                       # EXISTING: Core modules
â”‚   â”œâ”€â”€ parsers/               # âœ… Used by resume_service.py
â”‚   â”œâ”€â”€ analysis/              # âœ… Used by matching_service.py
â”‚   â”œâ”€â”€ vectorstore/           # âœ… Used by matching_service.py
â”‚   â”œâ”€â”€ rag/                   # âœ… Used by matching_service.py
â”‚   â”œâ”€â”€ generation/            # âœ… Used by generation_service.py
â”‚   â”œâ”€â”€ export/                # âœ… Used by generation_service.py
â”‚   â””â”€â”€ models.py              # âœ… Pydantic schemas
â”‚
â”œâ”€â”€ data/                      # EXISTING: Sample files
â”‚   â”œâ”€â”€ sample_resumes/        # Used for testing
â”‚   â””â”€â”€ sample_jds/            # Used for testing
â”‚
â”œâ”€â”€ output/                    # Generated files (DOCX)
â””â”€â”€ resume_builder.db          # SQLite database
```

---

## ğŸš€ **Testing the Integration**

### **Test Resume Parsing**

```bash
# 1. Start backend
python -m uvicorn backend.main:app --reload

# 2. Test endpoint
curl -X POST http://localhost:8000/api/resume/parse \
  -F "resume=@data/sample_resumes/Haswanth_Data_Engineer_Profile.pdf"

# Should return:
{
  "contact_info": {"name": "Haswanth", "email": "...", ...},
  "education": [...],
  "experience": [...],
  "skills": [...]
}
```

### **Test Manual Workflow**

```bash
curl -X POST http://localhost:8000/api/generate/manual \
  -H "Authorization: Bearer <token>" \
  -H "Content-Type: application/json" \
  -d '{
    "jd_text": "We are looking for a Data Engineer with Python, Spark, and AWS experience..."
  }'

# Should return optimized resume + match analysis + DOCX URL
```

### **Test Adzuna Search**

```bash
curl -X POST http://localhost:8000/api/jobs/search \
  -H "Authorization: Bearer <token>" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "data engineer",
    "location": "Atlanta, GA",
    "filters": {"salary_min": 80000}
  }'

# Should return list of jobs from Adzuna
```

---

## âœ… **Integration Checklist**

- [x] Backend service layer created (resume, jd, matching, generation, adzuna)
- [x] API routers created (resume, jobs, generation)
- [x] Main.py updated with new routers
- [x] User model extended (phone, address, resume_parsed_data)
- [x] Existing modules imported correctly (`sys.path.insert`)
- [ ] Database migration script (add new User columns) âš ï¸ **TODO**
- [ ] File upload handling (save to uploads/) âš ï¸ **TODO**
- [ ] Frontend services created (resumeService, jobService, generationService) âš ï¸ **TODO**
- [ ] Workflow UI pages (ManualWorkflow, AdzunaWorkflow) âš ï¸ **TODO**

---

## ğŸ¯ **Next Steps**

### **Immediate (Required for Registration):**
1. **Database Migration**:
   ```bash
   # Create migration script
   backend/migrations/002_add_user_fields.sql
   ```
   ```sql
   ALTER TABLE users ADD COLUMN phone VARCHAR(50);
   ALTER TABLE users ADD COLUMN address TEXT;
   ALTER TABLE users ADD COLUMN profile_pic_path VARCHAR(500);
   ALTER TABLE users ADD COLUMN resume_file_path VARCHAR(500);
   ALTER TABLE users ADD COLUMN resume_text TEXT;
   ALTER TABLE users ADD COLUMN resume_parsed_data JSON;
   ```

2. **Test Registration Flow**:
   - Start backend: `python -m uvicorn backend.main:app --reload`
   - Start frontend: `cd frontend && npm start`
   - Register new user with resume
   - Verify data in database: `sqlite3 resume_builder.db "SELECT * FROM users;"`

### **Next (Build Workflows):**
3. Create frontend workflow pages
4. Create frontend service files
5. Test end-to-end flows

---

**Last Updated:** 2025-12-16
**Integration Status:** 80% Complete (services ready, needs testing)
